{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cuadrados mínimos\n",
    "\n",
    "Para realizar un ajuste de una función por cuadrados mínimos,\n",
    "vamos a usar la función `curve_fit` de `scipy.optimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "plt.rc(\"figure\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "plt.rc(\"figure\", figsize=(6, 2))\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "Hay funciones especializadas para casos particulares,\n",
    "como los casos lineales,\n",
    "que son más eficientes.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivación\n",
    "\n",
    "Supongamos que tenemos una serie de $N$ mediciones $(x_i, y_i)$,\n",
    "y sabemos que están relacionadas por una dada función $f$:\n",
    "\n",
    "$$ y = f(x, p_1, \\ldots, p_k) $$\n",
    "\n",
    "donde $p_1, \\ldots, p_k$ son parámetros de la función\n",
    "que queremos determinar.\n",
    "\n",
    "Por ejemplo,\n",
    "supongamos que la función es $y = Ax$,\n",
    "y queremos determinar el parámetro $A$\n",
    "a partir de los siguientes datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = 3 * x  # la constante A es 3!\n",
    "\n",
    "plt.plot(x, y, marker=\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso,\n",
    "alcanzaría con dividir $y/x$\n",
    "para obtener $A$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y / x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero,\n",
    "estas \"mediciones\" son perfectas,\n",
    "sin ninguna incerteza.\n",
    "En la práctica,\n",
    "todas las mediciones tienen un error.\n",
    "\n",
    "Simulemos una medición agregándole error a los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_error = 1  # la desviación estándar\n",
    "y_medido = np.random.normal(y, scale=y_error)\n",
    "\n",
    "plt.plot(x, y, label=\"Ideal\")\n",
    "plt.scatter(x, y_medido, label=\"Medido\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tratamos de determinar $A$\n",
    "a partir de estas mediciones,\n",
    "no obtenemos exactamente $3$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_medido / x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos una pendiente $A$ distinta\n",
    "para cada medición.\n",
    "¿Cómo podemos unificarlas?\n",
    "\n",
    "Una opción \"incorrecta\" para combinarlas\n",
    "es hacer un promedio de estos valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_medido / x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero hay una manera más general de resolver este problema,\n",
    "que es realizar un ajuste por cuadrados mínimos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste por cuadrados mínimos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar un ajuste por cuadrados mínimos,\n",
    "vamos a usar la función `curve_fit` de `scipy.optimize`.\n",
    "\n",
    "`curve_fit` necesita (al menos) 3 parámetros:\n",
    "\n",
    "1. `f`, la función que queremos ajustar,\n",
    "2. `xdata`, el array de datos en $x$,\n",
    "3. `ydata`, el array de datos en $y$.\n",
    "\n",
    ":::{important}\n",
    "Es importante el orden de los parámetros al definir `f`.\n",
    "Primero va la variable `x`,\n",
    "y después los parámetros a determinar.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineal(x, A):\n",
    "    return A * x\n",
    "\n",
    "\n",
    "p_opt, p_cov = curve_fit(lineal, x, y_medido)\n",
    "\n",
    "p_opt, p_cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`curve_fit` devuelve dos valores:\n",
    "- `p_opt` es un array que contiene los valores óptimos de los parámetros,\n",
    "- `p_cov` es la matriz de covarianza de los parámetros.\n",
    "\n",
    "En este caso,\n",
    "- `p_opt` es un array de tamaño $1$ que contiene el valor óptimo de $A$,\n",
    "- `p_cov` es una matriz de $1\\times1$ que contiene la varianza de $A$.\n",
    "\n",
    "Entonces,\n",
    "podemos calcular el error de $A$\n",
    "como la raíz de la varianza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_optimo = p_opt[0]\n",
    "A_error = p_cov[0, 0] ** 0.5\n",
    "\n",
    "A_optimo, A_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor obtenido no da exactamente 3,\n",
    "pero el intervalo `A_optimo ± A_error` es compatible con $A=3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graficar el ajuste\n",
    "\n",
    "Para graficar el ajuste,\n",
    "podemos usar la misma función que le pasamos a `curve_fit`.\n",
    "La evaluamos en los datos `x` y el parámetro `A_optimo`.\n",
    "\n",
    "Para graficar los datos,\n",
    "se los suele graficar como puntos con barra de error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lineal(x, A_optimo)  # El \"y\" predicho a partir del ajuste\n",
    "\n",
    "plt.errorbar(x, y_medido, yerr=y_error, fmt=\"o\", label=\"Ajuste\")\n",
    "plt.plot(x, y_pred, label=\"Mediciones\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalmente,\n",
    "se acompaña este gráfico con\n",
    "el gráfico de los residuos.\n",
    "\n",
    "Los residuos $r_i$ son la diferencia entre\n",
    "la función $f(x_i)$\n",
    "y la medición $y_i$ correspondiente a dicho $x_i$:\n",
    "$$ r_i = y_i - f(x_i) $$\n",
    "donde se usan los parámetros óptimos para la función.\n",
    "\n",
    "Para graficar los residuos,\n",
    "se suele agregar un segundo gráfico debajo,\n",
    "ya que comparten en eje $x$.\n",
    "Es decir,\n",
    "$y_i$ y $r_i$ comparten el mismo $x_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lineal(x, A_optimo)\n",
    "residuos = y_medido - y_pred\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    2, 1, sharex=True, figsize=(6, 6), gridspec_kw={\"height_ratios\": (2, 1)}\n",
    ")\n",
    "\n",
    "ax[0].errorbar(x, y_medido, yerr=y_error, fmt=\"o\")\n",
    "ax[0].plot(x, y_pred)\n",
    "\n",
    "ax[1].errorbar(x, residuos, yerr=y_error, fmt=\"o\")\n",
    "ax[1].axhline(0, color=\"black\")\n",
    "\n",
    "ax[0].set(ylabel=\"Magnitud [unidad]\")\n",
    "ax[1].set(ylabel=\"Residuos [unidad]\", xlabel=\"Otra magnitud [otra unidad]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los residuos tienen la misma unidad que el eje $y$,\n",
    "y el residuo $r_i$ tiene el mismo error que la medición $y_i$.\n",
    "\n",
    "Los residuos nos permiten hacer un \"zoom\"\n",
    "a la diferencia entre las mediciones y la curva teórica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "Usando el siguiente conjunto de datos:\n",
    "\n",
    "```python\n",
    "y = np.array([11.5, 10.2, 10.4,  9.1,  8. ,  9.7, 10.2, 11.2, 11.2,  9.6])\n",
    "```\n",
    "\n",
    "ajustar por cuadrados mínimos\n",
    "una función constante,\n",
    "es decir,\n",
    "$f(x) = A$.\n",
    "\n",
    "Comparar el resultado contra\n",
    "el promedio $\\bar{x}$\n",
    "y el error del promedio $\\sigma_{\\bar{x}}$.\n",
    "\n",
    ":::{note}\n",
    "Para `x`,\n",
    "no debería importar los valores que se usan,\n",
    "mientras sea del mismo largo que `y`.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escriba aquí su solución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "solution_0"
   },
   "source": [
    "### Solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "y = np.array([11.5, 10.2, 10.4, 9.1, 8.0, 9.7, 10.2, 11.2, 11.2, 9.6])\n",
    "x = np.arange(y.size)\n",
    "\n",
    "\n",
    "def constante(x, A):\n",
    "    return A\n",
    "\n",
    "\n",
    "p_opt, p_cov = curve_fit(constante, x, y)\n",
    "\n",
    "A_opt = p_opt[0]\n",
    "A_error = p_cov[0, 0] ** 0.5\n",
    "\n",
    "promedio = np.mean(y)\n",
    "error_promedio = np.std(y, ddof=1) / np.size(y) ** 0.5\n",
    "# ddof=1 es para que divida por N-1 al calcular la desviación estándar\n",
    "\n",
    "print(\"                 A = \", A_opt)\n",
    "print(\"          promedio = \", promedio)\n",
    "print(\"        error de A = \", A_error)\n",
    "print(\"error del promedio = \", error_promedio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errores diferentes en `y`\n",
    "\n",
    "Por defecto,\n",
    "`curve_fit` asume que los errores en `y` son iguales.\n",
    "Pero,\n",
    "si cada `y` tiene un error distinto,\n",
    "podemos tenerlo en cuenta,\n",
    "para que le dé mayor peso a las mediciones con menor error.\n",
    "\n",
    "Por ejemplo,\n",
    "en los siguientes datos,\n",
    "las mediciones para `x=3` y `x=4`\n",
    "tienen 10 veces más incerteza\n",
    "que las mediciones para `x=1` y `x=2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "x = np.array([1, 2, 3, 4])\n",
    "y_error = np.array([1, 1, 10, 10])\n",
    "y = 3 * x\n",
    "y = np.random.normal(y, scale=y_error)\n",
    "\n",
    "plt.errorbar(x, y, yerr=y_error, fmt=\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Para pasarle los errores a `curve_fit`,\n",
    "hay que pasarle un array (del mismo tamaño que `ydata`)\n",
    "en el parámetro `sigma`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_opt, p_cov = curve_fit(lineal, x, y, sigma=y_error)\n",
    "\n",
    "A_opt = p_opt[0]\n",
    "A_err = p_cov[0, 0] ** 0.5\n",
    "\n",
    "plt.errorbar(x, y, yerr=y_error, fmt=\"o\", label=\"Mediciones\")\n",
    "plt.plot(x, lineal(x, A_opt), label=\"Ajuste\")\n",
    "plt.legend()\n",
    "\n",
    "A_opt, A_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si no los tenemos en cuenta,\n",
    "el valor que se obtiene es distinto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_opt, p_cov = curve_fit(lineal, x, y)\n",
    "\n",
    "A_opt = p_opt[0]\n",
    "A_err = p_cov[0, 0] ** 0.5\n",
    "\n",
    "plt.errorbar(x, y, yerr=y_error, fmt=\"o\", label=\"Mediciones\")\n",
    "plt.plot(x, lineal(x, A_opt), label=\"Ajuste\")\n",
    "plt.legend()\n",
    "\n",
    "A_opt, A_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al especificar las incertezas,\n",
    "`curve_fit` \"priorizó\" pasar más cerca de los puntos con menor error,\n",
    "resultando en una pendiente $A$ distinta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Múltiples parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recta(t, A, B):\n",
    "    return A * t + B\n",
    "\n",
    "\n",
    "x = np.linspace(0, 100, 10)\n",
    "y = 3 * x + 20\n",
    "y = np.random.normal(y)\n",
    "\n",
    "p_opt, p_cov = curve_fit(recta, x, y)\n",
    "p_err = np.sqrt(np.diag(p_cov))  # la raíz de la diagonal\n",
    "\n",
    "p_opt, p_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los parámetros están en el mismo orden\n",
    "que en la definición de la función (`recta`):\n",
    "```python\n",
    "A = p_opt[0]\n",
    "B = p_opt[1]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "Para evaluar la función,\n",
    "pueden usar `recta(x, *p_opt)`.\n",
    "Es equivalente a `recta(x, p_opt[0], p_opt[1])`,\n",
    "o, en general,\n",
    "`recta(x, p_opt[0], p_opt[1], ..., p_opt[n])`.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones no lineales\n",
    "\n",
    "Para usar cuadrados mínimos con funciones no lineales,\n",
    "hay que darle una ayuda al algoritmo,\n",
    "diciendode un punto inicial para que encuentre la solución.\n",
    "\n",
    "Una función es lineal para cuadrados mínimos\n",
    "si sus derivadas respecto de los parámetros no dependen de los parámetros.\n",
    "Por ejemplo:\n",
    "\n",
    "$$ f(x, A, B) = A \\sin(x) + B \\cos(x) $$\n",
    "\n",
    "es lineal,\n",
    "ya que\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "    \\frac{\\partial f}{\\partial A} = \\sin(x)\n",
    "    \\\\ \\\\\n",
    "    \\frac{\\partial f}{\\partial B} = \\cos(x)\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "En cambio,\n",
    "\n",
    "$$ f(x, A, w) = A \\sin(w x) $$\n",
    "\n",
    "pero no es lineal,\n",
    "ya que\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "    \\frac{\\partial f}{\\partial A} = \\sin(w x)\n",
    "    \\\\ \\\\\n",
    "    \\frac{\\partial f}{\\partial w} = w A \\cos(w x)\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generemos datos para esta función no lineal,\n",
    "con $A=2$ y $w=5$,\n",
    "y tratemos de ajustar sin darle parámetros iniciales para la busqueda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(t, A, w):\n",
    "    return A * np.sin(w * t)\n",
    "\n",
    "\n",
    "# Genero datos\n",
    "x = np.linspace(0, 2 * np.pi, 70)\n",
    "y = func(x, A=2, w=5)\n",
    "\n",
    "# Ajusto parámetros\n",
    "p, cov = curve_fit(func, x, y)\n",
    "\n",
    "# Grafico\n",
    "plt.plot(x, y, \"o\")\n",
    "plt.plot(x, func(y, *p))\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ni hace falta ver los residuos para saber que ajustó mal.\n",
    "\n",
    "Para pasarle los parámetros iniciales,\n",
    "hay que usar el parámetro `p0` de `curve_fit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (1, 5.3)\n",
    "p, cov = curve_fit(func, x, y, p0=p)\n",
    "\n",
    "plt.plot(x, y, \"o\")\n",
    "plt.plot(x, func(x, *p))\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note} Como estos datos no tienen incerteza,\n",
    "los residuos son exactamente 0,\n",
    "y el error de los parámetros también.\n",
    ":::\n",
    "\n",
    ":::{tip} Para saber si estamos dandole parámetros iniciales razonables,\n",
    "podemos comentar la linea de `curve_fit`,\n",
    "y graficar la función con los parámetros iniciales `p`.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (1, 5.3)\n",
    "# p, cov = curve_fit(func, x, y, p0=p)\n",
    "\n",
    "plt.plot(x, y, \"o\")\n",
    "plt.plot(x, func(x, *p))\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muchas veces se puede automatizar la elección de los parámetros iniciales.\n",
    "\n",
    "Por ejemplo,\n",
    "para $A$ podriamos usar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.max(y) - np.min(y)) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y para $w$,\n",
    "obtener una estimación a través de la distancia entre máximos.\n",
    "Los máximos se podrían encontrar con [`scipy.signal.find_peaks`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.find_peaks.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: bondad de ajuste\n",
    "\n",
    "### Gráfico de residuos\n",
    "\n",
    "Para analizar la bondad de ajuste,\n",
    "se puede analizar el gráfico de los residuos $r_i$,\n",
    "que son la diferencia entre la medición $y_i$ para un dado $x_i$,\n",
    "y el valor predicho por el modelo $f(x_i)$:\n",
    "\n",
    "$$ r_i = y_i - f(x_i) $$\n",
    "\n",
    "Debido a incertezas en la medición,\n",
    "esperamos que $y_i$ no sea exactamente igual al valor real.\n",
    "Si la función $f$ es el modelo correcto,\n",
    "es decir, el que describe a nuestro experimento,\n",
    "esperamos que una medición $y_i$ se \"pase\",\n",
    "para un lado o para el otro,\n",
    "del valor esperado $f(x_i)$.\n",
    "En otras palabras,\n",
    "esperamos que los residuos $r_i$ esten distribuidos alrededor de 0,\n",
    "de manea aleatoria.\n",
    "\n",
    "Por ejemplo,\n",
    "en la siguiente figura,\n",
    "solo en el caso de la primer columna se observan residuos aleatorios.\n",
    "En la segunda columna,\n",
    "el modelo real es una cuadrática;\n",
    "en la tercer columna,\n",
    "son dos lineales con un \"salto\" en el medio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def fit_and_plot(x, y, yerr, func, *, fig):\n",
    "    p, _ = curve_fit(func, x, y, sigma=yerr)\n",
    "    y_pred = func(x, *p)\n",
    "    residuos = y - y_pred\n",
    "\n",
    "    ax = fig.subplots(2, 1, sharex=True)\n",
    "    ax[0].errorbar(x, y, yerr=yerr, fmt=\".\")\n",
    "    ax[0].plot(x, y_pred, zorder=3)\n",
    "    ax[1].errorbar(x, residuos, yerr=yerr, fmt=\".\")\n",
    "    ax[1].axhline(0, color=\"black\")\n",
    "\n",
    "\n",
    "def recta(x, A, B):\n",
    "    return A * x + B\n",
    "\n",
    "\n",
    "x = np.arange(50)\n",
    "yerr = np.ones_like(x)\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "figs = plt.figure(figsize=(8, 3)).subfigures(ncols=3)\n",
    "\n",
    "y = recta(x, A=1, B=1) + rng.normal(scale=yerr)\n",
    "fit_and_plot(x, y, yerr, recta, fig=figs[0])\n",
    "\n",
    "y = 0.008 * x**2 + x + rng.normal(scale=yerr)\n",
    "fit_and_plot(x, y, yerr, recta, fig=figs[1])\n",
    "\n",
    "y = recta(x, A=1, B=1) + rng.normal(scale=yerr)\n",
    "y[x.size // 2 :] += 5\n",
    "fit_and_plot(x, y, yerr, recta, fig=figs[2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No es obvio verlo en los gráficos superiores,\n",
    "donde se grafican las mediciones (azul) y el modelo (naranja).\n",
    "Los residuos nos permiten hacer un \"zoom\",\n",
    "al considerar la diferencia entre estos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medidas de bondad\n",
    "\n",
    "Hay dos medidas relacionadas a los residuos,\n",
    "y tratan de resumir en un número si el ajuste es bueno:\n",
    "\n",
    "- el $\\chi^2$ (reducido)\n",
    "- el coeficiente de determinación $r^2$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\chi^2$ reducido\n",
    "\n",
    "El [$\\chi^2$ reducido](https://en.wikipedia.org/wiki/Reduced_chi-squared_statistic)\n",
    "es un indicador para la bondad del ajuste.\n",
    "El $\\chi^2$ es una suma pesada de las distancias (cuadráticas)\n",
    "de las mediciones $y_i$ al modelo $f$:\n",
    "\n",
    "$$ \\begin{align}\n",
    "\\chi^2\n",
    "&= \\sum_{i=1}^N \\left( \\frac{y_i - f(x_i)}{\\sigma_i} \\right)^2 \\\\\n",
    "&= \\sum_{i=1}^N \\left( \\frac{r_i}{\\sigma_i} \\right)^2\n",
    "\\end{align} $$\n",
    "\n",
    "donde $\\sigma_i$ es el error asociado a la medición $y_i$.\n",
    "Es decir, se calcula a partir de los residuos $r_i$.\n",
    "\n",
    "Para obtener el $\\chi^2$ reducido,\n",
    "dividimos por $N-k$,\n",
    "donde $N$ es la cantidad de mediciones\n",
    "y $k$ la cantidad de parámetros ajustados de nuestro modelo.\n",
    "\n",
    "$$ \\chi^2_r = \\frac{\\chi^2}{N - k} $$\n",
    "\n",
    "Por ejemplo,\n",
    "si se ajusta un modelo $y(x) = Ax + B$,\n",
    "entonces $k=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_reducido(x, y, func, params, *, y_err):\n",
    "    \"\"\"Calcula el chi^2 reducido a partir de los datos (x, y),\n",
    "    la función ajustada (`func`) y los parámetros óptimos (`params`).\n",
    "    \"\"\"\n",
    "    n_datos = y.size\n",
    "    n_params = len(params)\n",
    "    y_pred = func(x, *params)\n",
    "    residuos = y - y_pred\n",
    "    return np.sum((residuos / y_err) ** 2) / (n_datos - n_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coeficiente de determinación $r^2$\n",
    "\n",
    "El [coeficiente de determinación](https://en.wikipedia.org/wiki/Coefficient_of_determination)\n",
    "es una medida que nos da una idea de la variación en los datos que es explicada por el modelo.\n",
    "Mientras más cercana a $1$,\n",
    "una mayor proporcion de la variación en los datos es explicada por el modelo.\n",
    "\n",
    "En el caso de una regresión lineal,\n",
    "$f(x) = Ax + B$,\n",
    "es igual al cuadrado del [coeficiente de correlación de Pearson](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeficiente_de_determinacion(x, y, func, params):\n",
    "    \"\"\"Calcula el coeficiente de determinacion r^2 a partir de los datos (x, y),\n",
    "    la función ajustada (`func`) y los parámetros óptimos (`params`).\n",
    "    \"\"\"\n",
    "    y_pred = func(x, *params)\n",
    "    residuos = y - y_pred\n",
    "    return 1 - np.var(residuos) / np.var(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{warning}\n",
    "Calcular estos coeficientes no reemplaza a mirar los residuos.\n",
    "\n",
    "En el siguiente ejemplo,\n",
    "se ve que tanto el $\\chi^2$ como $r^2$ dan cercanos a $1$.\n",
    "Pero se observa una clara estructura sinusoidal en los residuos.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Simulamos las mediciones\n",
    "x = np.linspace(0, 2 * np.pi, 40)\n",
    "y = x + (1 / 7) * np.cos(5 * x)\n",
    "# Redondeamos a un decimal para simular una medición\n",
    "# con un error dado por la resolución instrumental\n",
    "y_medido = np.round(y, 1)\n",
    "y_error = np.full_like(y, 0.1)\n",
    "\n",
    "\n",
    "# Ajustamos por una función lineal\n",
    "# No es el modelo correcto, que tiene una parte sinusoidal\n",
    "def func(x, A, B):\n",
    "    return A * x + B\n",
    "\n",
    "\n",
    "p, cov = curve_fit(func, x, y_medido)\n",
    "y_pred = func(x, *p)\n",
    "residuos = y_medido - y_pred\n",
    "\n",
    "# Graficamos con los residuos\n",
    "fig, ax = plt.subplots(2, 1, sharex=True, figsize=(6, 5))\n",
    "\n",
    "ax[0].errorbar(x, y_medido, yerr=y_error, fmt=\".\")\n",
    "ax[0].plot(x, y_pred)\n",
    "\n",
    "ax[1].errorbar(x, residuos, yerr=y_error, fmt=\".\")\n",
    "ax[1].axhline(0, color=\"black\")\n",
    "\n",
    "# Calculamos los coeficientes de bondad de ajuste\n",
    "print(\"Chi^2 reducido:\", chi2_reducido(x, y_medido, func, p, y_err=y_error))\n",
    "print(\"           R^2:\", coeficiente_de_determinacion(x, y_medido, func, p))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "solution_0"
   ]
  },
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
